{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrgreen7/SYSC4906/blob/master/W2024/SYSC4415W24__A3_Student1_Student2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to Assignment 3 - Part 2 ü•≥\n",
        "\n",
        "\n",
        "---\n",
        "TA: Elmira Amooei\n",
        "\n",
        "Questions?: Rather than email, please ask any questions through the Discussion Board on Brightspace. That way, everyone can benefit from the answer\n",
        "\n",
        "** Deadline: See Brightspace end date**\n",
        "\n",
        "---\n",
        "\n",
        "### Working in teams of 2\n",
        "Complete Part 2 of Assignment 3 in the same team of two students that you formed in Part 1. A single submission per team is required on Brightspace.\n",
        "\n",
        "### Objective:\n",
        "In this assignment, we are going to listen to some jazz and disco!\n",
        "Yes, you read it right. We are using the GTZAN dataset to create a classifier that can tell what the music genre is! üé∑üé∏üéπüé∫\n",
        "\n",
        "\n",
        "### Details:\n",
        "In this part, you are going to implement two models.\n",
        "The first model is your own **proposed model** (the exact same one you proposed in Part One). And the second model is the **pretrained model** you selected in Part One.\n",
        "\n",
        "### Instructions:\n",
        "**DO NOT** wait to the last minute to complete this assignment as it can take hours hours to do this assignment if you are unfmiliar with Python and Machine Learning libraries.\n",
        "\n",
        "‚ùóYour solutions must be self-contained in this notebook; no other supplementary material or files will be accepted. As soon as I open your assignment's notebook , I will click \"runtime\" ‚Üí \"run all\". Ensure your notebook works properly without any errors and your results are clearly displayed, as instructed.\n",
        "\n",
        "**Dataset:**\n",
        "You are provided with two datasets on Brightspace, to be used in Parts 1 & 2 of Assignment. Download the dataset of your choice (*Note that you must use the dataset that you selected in your proposal in Assignment 3 Part 1*), store it in your Google Drive (you need a gmail account to do this). It should be under your \"My Drive\" (After uploading it to your Google Drive, check the location by right clicking on the file *-> File Information -> Details -> Location*).  **Do not** put it into any sub-folder as  I won't be able to run your code. It will raise an error and you will lose marks.\n",
        "\n",
        "**Metrics:**\n",
        "You must create a **confusion matrix** for each of the models you are implementing. A part of your assessment of this assignment is based on the language you use to *interpret what your confusion matrices are showing* and how you would *compare the performance of the two models* based on that.\n",
        "\n",
        "**Pytorch:** is what we used for Assignment 2, and we are using it here as well.\n",
        "\n",
        "**Q&A:**\n",
        "There are some question boxes in *markdown blocks* marked with (üéßüé∏) emojis. Your answers to these question blocks should go on the *markdown blocks* marked with (üìªüéπ) emojis. Just double-click on the emoji and you can start typing.*Note that I will skip over any text answers that are within the code blocks.*\n",
        "\n",
        "**Libraries:** You can add any library you might need that is not already imported. *If you are using a library that needs to be installed on Colab, please provide the command for it in the specified code block in Section 1.1 Initializations.*\n",
        "\n",
        "**Optional steps:** There are some code blocks marked as optional. However, feel free to really show your work and add in as much extra info as you want. This may result in bonus points based on what you are doing.üòâ\n",
        "Examples:\n",
        " * It is optional to use cross-validation in this assignment, but you will get a bonus point for implementing it. üéôÔ∏è\n",
        "\n",
        " * It is optional to use a grid search to tune your hyperparameters for your own model, but you will get a bonus point for implementing it. üéôÔ∏è\n",
        "\n",
        "\n",
        "**Runtime tips:** I suggest doing your coding and first making sure everything works fine on a CPU. Then do the actual model training on a GPU. To chage your runtime from CPU to GPU and vice versa, select **Runtime** -> **Change Runtime Type** -> under **Hardware accelerator** click on CPU or T4 GPU.\n",
        "\n",
        "**Submission:** Submit your Notebook as a *.ipynb* file that adopts this naming convention: ***SYSC4415W24_A3_Student1_Student2.ipynb*** on *Brightspace*. No other submission (e.g., through email) will be accepted. (Example file name: SYSC4415W24_A3_ElmiraAmooei_AnthonyFuller.ipynb)\n",
        "\n",
        "### Grading:\n",
        "Considering the fact that Elmira is really generous with marking and she wants to see if you understand the point of data exploration, pretraining, confusion matrix, etc., she is very strict with plagiarism. Therefore, for the text answers, she will not show mercy with **suspicious** cases and they will be sent to the Associate Dean for investigation. However, it is alright if you need to consult with Chat-GPT/online resources to figure out **some parts of the code**. Although, remember that I will see a huge ton of submissions that look identical and you might get unlucky! ‚ò†Ô∏è\n",
        "\n",
        "You will be evaluated on the performance your model achieved. Try to tune your model to achieve the best possible results you can. You are asked in a *markdown block* to explain what you attempted and explored. (Your work is not compared with any other teams, this is not a competition.)\n"
      ],
      "metadata": {
        "id": "GcaEf9LdAu9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initializations\n"
      ],
      "metadata": {
        "id": "rIzWURYdCos_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some basic ibraries you need are imported here. Make sure you include whatever library you need in this entire notebook in the code block below.\n",
        "\n",
        "*Note that you **DO NOT** need to use ```cv2``` or ```PIL``` at all! So, please figure out a simpler and more general way of plotting. They should not be imported or used in this notebook as you will be penalized.*"
      ],
      "metadata": {
        "id": "PyRG5AEHNILq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you are using any library that requires installation, please paste the installation command for it here.\n",
        "Leave the code block below if you are not installing any libraries."
      ],
      "metadata": {
        "id": "hXYKklNMNpbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries to install - leave this code block blank if this does not apply to you\n",
        "# Please add a brief comment on why you need the library and what it does\n"
      ],
      "metadata": {
        "id": "CrxZ_P9tNkln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries you might need\n",
        "# General\n",
        "import os\n",
        "import zipfile\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# For preproccessing\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# For modeling\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchsummary\n",
        "\n",
        "# For metrics\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import  precision_score\n",
        "from sklearn.metrics import  recall_score\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import  classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import  roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "t3_N_y3sNfTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block will mount google drive.\n",
        "\n",
        "*It will open a new window to get authorizations to use your Google Drive. Just follow the steps. This is a standard process*"
      ],
      "metadata": {
        "id": "NrqW4lPqC0ov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aah6KMLMArdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1f8526-5263-4b75-986e-e8602fdc7537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Create path\n",
        "\n",
        "*If you absolutely need to change the paths, please do it on the code block below only **and the code block below only**. Because I will run your notebook and if you have other paths defined anywhere else it will raise errors and you will lose mark.*"
      ],
      "metadata": {
        "id": "LVbYrnQEClvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path for extractions\n",
        "zip_file_paths = ['/content/drive/My Drive/GTZAN Genre Collection.zip',\n",
        "                  '/content/drive/My Drive/GTZAN Genre Collection Spectrograms.zip']\n",
        "\n",
        "dataset_dirs = ['/content/drive/My Drive/GTZAN Genre Collection',\n",
        "                '/content/drive/My Drive/GTZAN Genre Collection Spectrograms']\n",
        "\n",
        "for zip_file_path, dataset_dir in zip(zip_file_paths, dataset_dirs):\n",
        "    if os.path.exists(zip_file_path):\n",
        "        print(f\"Extracting {zip_file_path} to {dataset_dir}\")\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(dataset_dir)\n",
        "    else:\n",
        "        print(f\"Zip file {zip_file_path} does not exist.\")\n"
      ],
      "metadata": {
        "id": "aX7IZIh0Cl_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Load your data and see how it looks\n",
        "\n",
        "The minimum details you need to provide are:\n",
        "\n",
        "1.   Show how many categories/classes there are in the dataset using ```print()```,\n",
        "2.   Show how many samples are present in each category using ```print()```,\n",
        "2.   Plot the class distributions for the dataset using ```matplotlib```,\n",
        "\n"
      ],
      "metadata": {
        "id": "LOB2RNkII-RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a count of the samples\n"
      ],
      "metadata": {
        "id": "qBMmiSVTOhgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the class distributions\n"
      ],
      "metadata": {
        "id": "Sp1XuomLPuQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Any additional data visualizations or exploratory analysis - This is optional, but highly recommended\n"
      ],
      "metadata": {
        "id": "aO37q7ToPxMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocessing\n",
        "\n",
        "The minimum you need here is to:\n",
        "1. Create your DataLoaders,\n",
        "2. Create train and test splits.\n",
        "\n",
        "Please do normalization/scaling or any additional proposed preproccessing here (Including anyt preprocessing steps you have included in your proposal.)\n"
      ],
      "metadata": {
        "id": "3vX4Z_nNI6BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Any additional preproccessing\n"
      ],
      "metadata": {
        "id": "5tSc4kOsghn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test\n",
        "# Hint: This is very similar to assignment 2\n"
      ],
      "metadata": {
        "id": "KT-vxP0QI74n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Any additional preproccessing\n"
      ],
      "metadata": {
        "id": "gE71Je3yghfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Your proposed model"
      ],
      "metadata": {
        "id": "L2f2stNqCmP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéßüé∏ Explain the steps you took to tune your model and how each step affected your performance. (This answer can be as detailed as you want, don't keep it short.)\n",
        "\n",
        "* In case you are using grid search for hyperparamter tuning: Why and how are you choosing the grid limits/steps? Give details."
      ],
      "metadata": {
        "id": "feUcU4mCl2rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìªüéπ"
      ],
      "metadata": {
        "id": "wCflqx2RC7hP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to add in more code blocks. Please include some comments on what you are doing within the code.\n",
        "\n",
        "*Add comments to describe the key concepts of the code and its function. It does not need to be line-by-line. Keep it short.*"
      ],
      "metadata": {
        "id": "Y3eOrZAElyrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model\n"
      ],
      "metadata": {
        "id": "39xoFUPMg_zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n"
      ],
      "metadata": {
        "id": "ulEmJSCDg_uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n"
      ],
      "metadata": {
        "id": "1pZm_3bdCmfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model suign one chosen metric"
      ],
      "metadata": {
        "id": "kmvQLbyBhZSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot the confusion matrix\n"
      ],
      "metadata": {
        "id": "7RI4se0ThPoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Your pretrained model"
      ],
      "metadata": {
        "id": "lyY4lATzCmsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The library below is a great source that possibly covers your proposed pretrained model selected in your proposal. There is a link provided that covers an example implementation. It's very straightforward and needs minimum tweaks.\n",
        "\n",
        "[Pytorch pretrained models](https://pytorch.org/vision/stable/models.html)"
      ],
      "metadata": {
        "id": "RT-k7N5aisLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained models and pretrained weights\n",
        "import torchvision.models as models\n"
      ],
      "metadata": {
        "id": "QCq6n5_FjJef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to adjust the code blocks in this section as you see fit.\n",
        "\n",
        "\n",
        "**Note that your code needs to run flawlessly. (If you are using any pretrained model that is not covered in the library above.) Therefore, please make sure you have every required installations and libraries imported under section 1.1.**"
      ],
      "metadata": {
        "id": "_T16yokijI2P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q82GuUEmcewk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pretrained model\n"
      ],
      "metadata": {
        "id": "c7A5XTqrCnCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n"
      ],
      "metadata": {
        "id": "z33PNv77iwN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n"
      ],
      "metadata": {
        "id": "5tfBsrMqiwLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model using the same chosen metric as your own model\n"
      ],
      "metadata": {
        "id": "10N4ZEGjiwIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot the confusion matrix\n"
      ],
      "metadata": {
        "id": "gqT7Yv7ci1qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparisons"
      ],
      "metadata": {
        "id": "Epe9T_j2HwCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéßüé∏ How did you compare your proposed model and the pretrained model in terms of performance? Is your model doing a better/worse job than the pretrained model? Why?\n",
        "Describing confusion matrices is neccessary to answer this question.\n",
        "You can also include other metrics, such as accuracy, train-time, etc."
      ],
      "metadata": {
        "id": "MG9_BGQrG1go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìªüéπ"
      ],
      "metadata": {
        "id": "5_rpJ8GoHoMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéßüé∏ What will you do differently? Why?\n",
        "> In terms of the dataset, preproccessing, modeling, etc."
      ],
      "metadata": {
        "id": "VXJp36ueHz63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìªüéπ"
      ],
      "metadata": {
        "id": "eLEbRjC0Hz0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All done! üé∂üíÉüï∫"
      ],
      "metadata": {
        "id": "s7MEXMV4D_f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Optional challenge!\n",
        "\n",
        "You are not graded for this part, but I will provide feedback if you gave it a shot!\n",
        "\n",
        "Believe me, it is a cool piece üé∫"
      ],
      "metadata": {
        "id": "U408RMznH8U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As your model can classify music genres, can you challenge yourselves to have your model listen to you playing a piece of music (e.g., on Spotify) and classify its genre in real-time?\n",
        "\n",
        "**Hint 01:** ```pyaudio``` is a library you can use.\n",
        "\n",
        "**Hint 02:** You need to do the same preproccessing on the live data as you did for your model.\n",
        "\n",
        "**Hint 03:** You need to put your model into the ```.eval()``` state. Don't forget to save the model weights so that you can do load it using ```model.load_state_dict(torch.load('MyModel_weights.pth'))```\n",
        "\n",
        "**Hint 04:** Your code block needs to listen to the music you are playing, so maybe you can put it in a ```try: while True:``` and ```except KeyboardInterrupt``` loop."
      ],
      "metadata": {
        "id": "SovathB7IA_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Iil9TquJLjEn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}